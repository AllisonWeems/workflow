
# Project workflow

See our [example](https://github.com/dcl-docs/project-example) for an example of a project that uses the workflow.

## Project template

We've created a project template with our suggested folder organization and a sample Makefile. You can quickly create a project using this template with the dcl package. If you haven't already, install the dcl package:

```{r, eval=FALSE}
# install.packages("devtools")
devtools::install_github("stanford-datalab/dcl")
```

The function `dcl::create_data_project(path = "PROJECT/PATH")` will create a directory at `PROJECT/PATH` will the following files and directories:

* __data__: cleaned data
* __data-raw__: raw data
* __docs__: data documentation and notes
* __eda__: exploratory data analysis on your cleaned data
* __scripts__: data-cleaning scripts
* __reports__: findings to present to others
* __Makefile__
* __.gitignore__
* __README.md__

We'll discuss how to use these directories and files in the next section.

By default, `dcl::create_data_project()` creates an RStudio project for the directory. If you don't want to create an RStudio project, set the `project` argument to `FALSE`:

```{r eval=FALSE}
dcl::create_data_project(path = "PROJECT/PATH", project = FALSE)
```

Note that it's generally a bad idea to nest RStudio projects. If you find yourself wanting to use our folder organization inside a different RStudio project, you'll probably want `project = FALSE`. 

`dcl::create_data_project()` will print out a series of messages to the console that will look something like:

```{r echo=FALSE, out.height='40%'}
knitr::include_graphics(
  "images/project-workflow/console-messages.png", dpi = image_dpi
)
```

These messages tell you what files and sub-directories are being written to your new project directory. If `project = TRUE`, the messages will also tell you about the creation of the project. 

## Setup GitHub

We recommend using GitHub for all your data work. Generally, you'll want one repository per project. 

Here, we'll explain how to setup git and GitHub for your newly created project. Note that this is a different workflow than you might have used in the past--instead of creating a repository on GitHub and then cloning it, we created a local directory first, and now want to create a corresponding GitHub repository. 

The following steps will only work if you set `project = TRUE` in the previous section because they require a .Rproj file. However, if you didn't want an RStudio project for your project, you probably also don't want a GitHub repository for it either. 

### Create a GitHub token

You will need a GitHub personal access token in order to setup git and GitHub from RStudio. Open [GitHub](http://github.com/) in your browser. Then:

* Click on your profile picture in the upper righthand corner, then click on _Settings_.

```{r echo=FALSE}
knitr::include_graphics(
  "images/project-workflow/github-pat-1.png", 
  dpi = image_dpi_small
)
```

* Then, go to _Developer Settings_ > _Personal access tokens_.
* Click _Generate new token_.

```{r echo=FALSE}
knitr::include_graphics(
  "images/project-workflow/github-pat-2.png", 
  dpi = image_dpi_small
)
```

* Name your token something like "RStudio" or "R." The name doesn't really matter--it's just a way to keep track of your different tokens. Under _Scopes_, select _repo_ (you'll only need the repo scope for this chpater, but you can select other scopes if you anticipate using the GitHub API in more scenarios.)

```{r echo=FALSE}
knitr::include_graphics(
  "images/project-workflow/github-pat-3.png", 
  dpi = image_dpi
)
```

* Scroll down to the bottom, then click _Generate token_.

```{r echo=FALSE}
knitr::include_graphics(
  "images/project-workflow/github-pat-4.png", 
  dpi = image_dpi_small
)
```

* Copy the resulting token to your clipboard and return to RStudio.
* From the RStudio console, open your .Renviron with

```{r eval=FALSE}
usethis::edit_r_environ()
```

* Add the following line to your .Renviron, replacing `YOUR_TOKEN` with the token you copied earlier.

```{r eval=FALSE}
GITHUB_PAT=YOUR_TOKEN
```

* Restart R (_Cmd/Ctrl_ + _Shift_ + _F10_). 

### `use_git()`

If you haven't already, open your project in RStudio. Then, run

```{r eval=FALSE}
usethis::use_git()
```

in the console. `use_git()` will set up a Git repository for your project, then ask you if you want to make an initial commit:

```{r echo=FALSE}
knitr::include_graphics(
  "images/project-workflow/use-git-1.png", 
  dpi = image_dpi_small
)
```

Enter the number that corresponds to the "Yes" option. Here, that's `3`, but it might be different for you.

Next, you'll be prompted to restart RStudio:

```{r echo=FALSE}
knitr::include_graphics(
  "images/project-workflow/use-git-2.png", 
  dpi = image_dpi_small
)
```

Again, select the "Yes" option. 

### `use_github()`

Now, you've initialized a Git repository, but haven't yet connected that repository to GitHub. Run the following code to connect your repository to GitHub:

```{r eval=FALSE}
usethis::use_github()
```

Note that `use_github()` has multiple optional arguments that allow you to, for example, create the repository under an organization or make the repository private. 

You'll be prompted for a git protocol. You'll probably want ssh.

```{r echo=FALSE}
knitr::include_graphics(
  "images/project-workflow/use-github-1.png", 
  dpi = image_dpi
)
```

Next, you'll be prompted to verify the repository name and description. Say _Yes_ unless you're unhappy with them (although note that you can always change them later).

You might get the following error:

```{r echo=FALSE, out.width='40%'}
knitr::include_graphics(
  "images/project-workflow/use-github-2.png", 
  dpi = image_dpi
)
```

* If so, copy the recommended command.

```
git push --set-upstream origin master
```

* Then, open Terminal, navigate to your project directory, paste in your copied command, and press enter. 

```{r echo=FALSE, out.width='40%'}
knitr::include_graphics("images/project-workflow/git-fix.png", dpi = image_dpi)
```

This command sets the default location that `git push` will push to. 

* Earlier, `use_github()` opened your GitHub repository in the browser. To see the result of your push, refresh the page. Your files should appear. 

Your setup is complete! Now, we'll go into more detail about how to use the folders and Makefile created by `dcl::create_data_project()`. 

## Folder organization

The following sections explain the contents of each folder in more detail. Here's an overview:

```{r echo=FALSE}
knitr::include_graphics(
  "images/project-workflow/folder-organization.png", dpi = image_dpi
)
```


### data-raw

This folder is for your raw data (i.e., the data that you haven't touched yet). 

For each data file, come up with a short, but descriptive, name. You'll use these names to name other files. For example, our [project example](https://github.com/dcl-docs/project-example/tree/master/data-raw) contains the following raw data files:

* __birds.txt__
* __collisions.csv__
* __light_mp.csv__

Generally, you don't want to push data to GitHub, so the .gitignore specifies that git should ignore all files in __data-raw__. 

### scripts

This folder is for your data-cleaning scripts. If you're unfamiliar with R scripts, see [Chapter 4](https://dcl-workflow.stanford.edu/scripts.html). Each script will read in a raw data file, process it, and then write the an .rds file to __data__. 

You should have one script for each raw data source. Name each script the same name as the raw data source. For example, the script __collisions.R__ reads in _collions.csv__, cleans the data, then writes _collions.rds_ to __data__ using `readr::write_rds()`. 

If you want to join multiple data sources, create an additional script that joins the cleaned data files. For example, __bird_collisions_light.R__ joins __birds.rds__, __collisions.rds__, and __light_mp.rds__, and writes to __bird_collisions_light.rds__. As the diagram points out, your joining scripts can join cleaned data from __data__. 
  
### data

This folder contains cleaned data (in .rds format) that is ready to analyze. Each .rds file should have the same name as its corresponding raw data file and cleaning script.

If you joined data, that cleaned data should be here too. The cleaned and joined data should have the same name as the script that carried out the joining. For example, our example project's __data__ folder has the following files:

* _birds.rds_
* _collisions.rds_
* _light_mp.rds_
* _bird_collisions_light.rds_

### docs

The __docs__ folder is for any documentation files you used to understand the data, as well as for any notes you have on the data or your plan for analysis. 

### eda

The __eda__ folder contains R Markdown files with your EDA work. Create one R Markdown file for each cleaned data set that you want to explore.

Again, match the names of these files to your data files and cleaning scripts. For example, __birds.Rmd__ performs EDA on just __birds.rds__, __bird_collisions_light.Rmd__ performs EDA on just __bird_collisions_light.rds__, etc. This separation is intended to help you organize your EDA, which can become unwieldy if all placed in a single file.   

### reports

This folder contains reports on your data. These don't need to be named according to the convention of the other files. For example, our __reports__ folder just has one report called __report.Rmd__. 

## `here::here()`

Say you want to give the file path for __collisions.csv__ in __collisions.R__. One way to specify the file would be to give the file path relative to the scripts folder: `"../data-raw/collisions.csv"`. However, this will only work if you set your working directory to the __scripts__ folder every time you run your script. It also means you have to think about where folders are located relative to each other.

The [here package](https://here.r-lib.org/) makes this process easier. The function `here::here()` allows you to specify a file path relative to the directory of your .Rproj file, no matter what folder you're in. For example, no matter where you are in your project, you can give the file path of __collisions.csv__ as `here::here("data-raw/collisions.csv")`. 


See the example [scripts](https://github.com/dcl-docs/project-example/tree/master/scripts), [EDA documents](https://github.com/dcl-docs/project-example/tree/master/eda), and [reports](https://github.com/dcl-docs/project-example/tree/master/reports) for more examples.

## R Markdown template

The dcl package also contains a R Markdown template to use for your EDA files and reports. To use the template:

* Click on the new file button in the top-left corner of RStudio.
* Select _R Markdown_ > _From Template_ > _DCL GitHub Document_. 

Our template is similar to the default GitHub document template, but:

* Includes a table of contents by default.
* Formats the first R chunk to highlight places for libraries, parameters, and reading in code.
* Has example headers.

## Make

Imagine that __birds.txt__, our example raw data set, gets updated. Maybe the original owners added new birds or corrected a mistake that they noticed. __birds.rds__, our cleaned version of this data, depends on __birds.txt__. __bird_collisions_light.rds__, our cleaned and joined data, also depends on __birds.txt__, as do some of our EDA files and reports. To update all these files, we could rerun __birds.R__ to regenerate __birds.rds__ and __bird_collisions_light.R__ to regenerate __bird_collisions_light.rds__. Then, we could re-knit the relevant EDA files and reports so that they use the updated data. However, manually updating all our files can get tedious. It also requires remembering which files depend on each other, which can get complicated. 

_Makefiles_ are a better way to keep track of dependencies and update files when there are changes. We've created a makefile for this example project. It specifies which files depend on each other, as well as what to do when certain files changes (e.g., run the script or knit the R Markdown file).

Makefiles are read by a program called Make. Make looks for changes in the files specified in the makefile. Then, it rebuilds the files that depend on the files that changed, based on the dependency structure given in the makefile.

Importantly, Make will only rebuild files affected by a change. For example, say __birds.txt__ changes. Because of how our makefile is set up, Make will re-rerun __birds.R__ and __bird_collisions_light.R__, which will re-write to __birds.rds__ and __bird_collisions_light.rds__. Then, Make will re-knit the EDA files __birds.Rmd__ and __bird_collisions_light.Rmd__, as well as our report __report.Rmd__. However, it will not re-rerun __collisions.R__, re-knit __collisions.Rmd__, etc., because these other files do not depend on __birds.txt__.

[GNU Make](https://www.gnu.org/software/make/) is free software and comes installed on Macs and most Unix machines. If you're a Windows user, you might need to install Make yourself. The following will explain how to use the makefile we have provided in this repo. The [GNU Make manual](https://www.gnu.org/software/make/manual/) is a reference where you can learn more.

### Running Make

To run Make, navigate to your project directory from the command line. Then, type `make` and hit enter. Note that this won't work for your specific project until you create your own makefile by following the instructions below. 

### Creating a makefile

You'll need to edit the example makefile in order for Make to work for you. If you're using our recommended folder organization, you should be able to re-use a lot of the example file.

#### Search path
  
`VPATH = data data-raw eda reports scripts`
  
This variable provides the names of all the folders where Make should look for your files. If you used our recommended folder organization, you shouldn't have to change anything. If you used different folder names (or have additional folders), just change the names. Make sure to separate the folders with a single space.

#### Targets
    
`all : $(DATA) $(EDA) $(REPORTS)` on line 14 defines a _target_ called `all`. This tells Make to, by default, consider all the files defined by `DATA`, `EDA`, and `REPORTS`. 

If you used the recommended folder organization, you won't need to change line 14. However, you will need to change the definitions of `DATA`, `EDA`, and `REPORTS` on lines 4-11 to contain the names of the files you'd like Make to monitor and automatically update. 
    
#### Dependencies

Now, you need to specify the _dependencies_ of your project. Lines 16-27 define our dependencies. 

File A depends on File B if changing File B can change File A. For example, `birds.md` depends on `birds.rds` because changing the cleaned data in `birds.rds` could change the analysis, visualizations, etc. in `birds.md`.

Create a line for each file in your project that depends on at least one other file. Specify the dependencies by using the following syntax:

`[target file] : [dependency file 1] [dependency file 2] [dependency file 3]`

Your files can have any number of dependencies, but make sure to separate the dependencies with a single space. If you need more than one line for your dependencies, end all lines except the last with a "\\".

#### Rules

Finally, you need to tell Make how to update different types of files. We want Make to run a script if raw data changes, but knit an R Markdown document if cleaned data changes. Lines 30-33 define our rules. 

You probably won't need to update these rules, but it's useful to understand them. 

The first rule (lines 30-31) tells Make how to update a .rds file. For example, say __birds.txt__ changes. Make knows that __birds.rds__ depends on __birds.txt__ because of our specified dependencies. Make then looks to our first rule to figure out how to update __birds.rds__. The rule says to run the R script with the same name as the .rds file. In our example, that script is __birds.R__, so Make will run __birds.R__.

The second rule (32-33) tells Make how to update a .md file. The rule tells Make to knit the .Rmd version of the relevant .md file. For example, if __birds.md__ needs updating (because __birds.rds__ changed), Make will knit __birds.Rmd__.
